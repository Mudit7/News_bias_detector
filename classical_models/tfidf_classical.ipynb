{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xml.sax\n",
    "import xml.parsers.expat\n",
    "import time \n",
    "import pickle\n",
    "import os\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "root_path = '/Users/mudit/anlp/News_bias_detector/'\n",
    "def split_train_test_df(df,tr,te):\n",
    "  total_rowsn=df.shape[0]\n",
    "\n",
    "  train_rowsn=int(total_rowsn*tr/100)\n",
    "  return df[0:train_rowsn],df[train_rowsn+1:total_rowsn]\n",
    "\n",
    "def split_train_test_arr(arr,tr,te):\n",
    "  total_rowsn=arr.shape[0]\n",
    "\n",
    "  train_rowsn=int(total_rowsn*tr/100)\n",
    "  return arr[0:train_rowsn,:],arr[train_rowsn+1:total_rowsn,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645 645 645\n"
     ]
    }
   ],
   "source": [
    "text=[]\n",
    "labels = []\n",
    "titles = []\n",
    "class ParseHandler(xml.sax.handler.ContentHandler):\n",
    "    def __init__(self):\n",
    "        self.text=\"\"\n",
    "    def startElement(self, name, attrs):\n",
    "        self.CurrentData = name\n",
    "        if(self.CurrentData==\"article\"):\n",
    "            labels.append(attrs['hyperpartisan'])\n",
    "\n",
    "\n",
    "\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setFeature(xml.sax.handler.feature_namespaces, 0) \n",
    "Handler = ParseHandler()\n",
    "parser.setContentHandler(Handler)\n",
    "parser.parse(root_path+\"article_labels.xml\")\n",
    "\n",
    "\n",
    "import re\n",
    "class ParseHandler1(xml.sax.handler.ContentHandler):\n",
    "    def __init__(self):\n",
    "        self.text=\"\"\n",
    "        self.r1=0\n",
    "    def startElement(self, name, attrs):\n",
    "        self.CurrentData = name\n",
    "        if 'title' in attrs.getNames():\n",
    "            titles.append(attrs.getValue('title'))\n",
    "    def endElement(self, name):\n",
    "        if(name==\"article\"):\n",
    "            self.text=clean_text(self.text)\n",
    "            self.text=re.sub(r'([^\\s\\w]|_)+', '', self.text)\n",
    "            self.text=self.text.strip()\n",
    "            text.append(self.text)\n",
    "            self.text=\"\" \n",
    "        \n",
    "    def characters(self, data):\n",
    "        self.text += data\n",
    "\n",
    "def clean_text(text1):\n",
    "    text1 = text1.replace(\".\", \". \")\n",
    "    text1 = text1.replace(\" _\", \" \")\n",
    "    text1 = text1.replace(\"  \", \" \")\n",
    "    text1 = text1.replace(\". . . .\", \"...\")\n",
    "    text1 = text1.replace(\". . .\", \"...\")\n",
    "    return text1\n",
    "\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setFeature(xml.sax.handler.feature_namespaces, 0) \n",
    "Handler = ParseHandler1()\n",
    "parser.setContentHandler(Handler)\n",
    "parser.parse(root_path+\"articles-training.xml\")\n",
    "\n",
    "print(len(titles),len(labels),len(titles))\n",
    "\n",
    "# import pandas as pd \n",
    "# df1 = pd.DataFrame(text)\n",
    "# df2=pd.DataFrame(labels)\n",
    "# # print(df1)\n",
    "# result = pd.concat([df1, df2], axis=1, sort=False) \n",
    "# result.columns = ['texts','labels']\n",
    "# result.to_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "texts = df['texts']\n",
    "labels_df = df['labels']\n",
    "\n",
    "train_df,test_df = split_train_test_df(texts,80,20)\n",
    "train_labels_df,test_labels_df = split_train_test_df(labels_df,80,20)\n",
    "\n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    "\n",
    "train_tfidf_vectors=tfidf_vectorizer.fit_transform(train_df)\n",
    "test_tfidf_vectors = tfidf_vectorizer.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear kernel\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.84      0.86        98\n",
      "        True       0.56      0.67      0.61        30\n",
      "\n",
      "    accuracy                           0.80       128\n",
      "   macro avg       0.72      0.75      0.73       128\n",
      "weighted avg       0.81      0.80      0.80       128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lin_clf = LinearSVC(penalty='l1',dual=False)\n",
    "lin_clf.fit(train_tfidf_vectors, train_labels_df.to_numpy())\n",
    "test_tfidf_vectors = tfidf_vectorizer.transform(test_df)\n",
    "out = lin_clf.predict(test_tfidf_vectors)\n",
    "print('Linear kernel\\n', classification_report(out,test_labels_df.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mudit/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with RBF kernel\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.72      0.84       128\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.72       128\n",
      "   macro avg       0.50      0.36      0.42       128\n",
      "weighted avg       1.00      0.72      0.84       128\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mudit/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rbfclf = SVC(kernel = 'rbf',degree=3)\n",
    "rbfclf.fit(train_tfidf_vectors, train_labels_df.to_numpy())\n",
    "\n",
    "out = rbfclf.predict(test_tfidf_vectors)\n",
    "print('SVM with RBF kernel\\n', classification_report(out,test_labels_df.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.80      0.86       106\n",
      "        True       0.42      0.68      0.52        22\n",
      "\n",
      "    accuracy                           0.78       128\n",
      "   macro avg       0.67      0.74      0.69       128\n",
      "weighted avg       0.84      0.78      0.80       128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_clf = RandomForestClassifier(n_estimators=100)\n",
    "rfc_clf.fit(train_tfidf_vectors, train_labels_df.to_numpy())\n",
    "\n",
    "out = rfc_clf.predict(test_tfidf_vectors)\n",
    "print('Random Forest Classifier\\n', classification_report(out,test_labels_df.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.68      0.79      0.73        80\n",
      "        True       0.53      0.40      0.45        48\n",
      "\n",
      "    accuracy                           0.64       128\n",
      "   macro avg       0.61      0.59      0.59       128\n",
      "weighted avg       0.63      0.64      0.63       128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "ada_clf.fit(train_tfidf_vectors, train_labels_df.to_numpy())\n",
    "\n",
    "out = ada_clf.predict(test_tfidf_vectors)\n",
    "print('Adaboost\\n', classification_report(out,test_labels_df.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
